{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hand writing digit recognition",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1x_ABQmeoDFLIbfz4Qip8219pG0O4Nazg",
      "authorship_tag": "ABX9TyN3t/UuilR4kqpb95pje8N9"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "hPP501T5tyqC",
        "outputId": "2b17edf1-3e71-410b-d0dd-55b6069900e4"
      },
      "source": [
        "!pip install kaggle\r\n",
        "from google.colab import files \r\n",
        "files.upload() #download and upload json file"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.10)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.12.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c1c59def-2684-478a-9ecb-df4594f66c73\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c1c59def-2684-478a-9ecb-df4594f66c73\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle (1).json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"samratalam\",\"key\":\"cad80de460ce88e637f7223e78a7ab03\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9NkJF4mt-KA"
      },
      "source": [
        "\r\n",
        "!mkdir -p ~/.kaggle\r\n",
        "!cp kaggle.json ~/.kaggle/\r\n",
        "\r\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGFLsIr0uZIb",
        "outputId": "2a72f8db-bbbd-49c9-a5ca-e35d4b188977"
      },
      "source": [
        "!kaggle competitions download -c digit-recognizer"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.10 / client 1.5.4)\n",
            "train.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "sample_submission.csv: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-SnlEMGuBjo",
        "outputId": "9b9ab4a2-9cdd-4edc-91c3-17802b806237"
      },
      "source": [
        "#to unzip file\r\n",
        "\r\n",
        "from zipfile import ZipFile\r\n",
        "file_name= \"train.csv.zip\"\r\n",
        "\r\n",
        "with ZipFile(file_name ,'r') as zip:\r\n",
        "  zip.extractall()\r\n",
        "  print('Done')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cGAZmAVu1oX",
        "outputId": "5a339b58-8ed1-4334-9ae7-c2bee2a7547d"
      },
      "source": [
        "#to unzip file\r\n",
        "\r\n",
        "from zipfile import ZipFile\r\n",
        "file_name= \"test.csv.zip\"\r\n",
        "\r\n",
        "with ZipFile(file_name ,'r') as zip:\r\n",
        "  zip.extractall()\r\n",
        "  print('Done')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKffBNr2wSBx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71f17f93-3197-4d49-86dc-9e4b15b7a10b"
      },
      "source": [
        "#import library\r\n",
        "\r\n",
        "#ignore warnig\r\n",
        "import warnings\r\n",
        "warnings.warn('ignore')        ########################\r\n",
        "\r\n",
        "#handel tabel like data and metrices\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import math\r\n",
        "import itertools\r\n",
        "\r\n",
        "#visualization\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "#modeling helper\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "#deep learnig libraries\r\n",
        "from keras.models import Sequential , load_model\r\n",
        "from keras.layers import Dense,Conv2D,MaxPool2D,BatchNormalization,Flatten,Dropout\r\n",
        "from keras.optimizers import Adam\r\n",
        "\r\n",
        "#preprocessing\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "\r\n",
        "\r\n",
        "from keras.utils import to_categorical\r\n",
        "\r\n",
        "from keras.callbacks import LearningRateScheduler\r\n",
        "from keras.callbacks import EarlyStopping\r\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: ignore\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utPSGbrkrc66"
      },
      "source": [
        "#loading data\r\n",
        "train = pd.read_csv('/content/train.csv')\r\n",
        "test = pd.read_csv('/content/test.csv')\r\n",
        "\r\n",
        "train_df = train.copy()\r\n",
        "test_df = test.copy()"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "tHI0Y-xmsliv",
        "outputId": "c7918b98-ef17-4b64-ff6f-2b3ed8149982"
      },
      "source": [
        "#havig a look at the data\r\n",
        "train_df.describe()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel744</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.00000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.00000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.00000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.000000</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "      <td>42000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4.456643</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00300</td>\n",
              "      <td>0.011190</td>\n",
              "      <td>0.005143</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000381</td>\n",
              "      <td>0.001310</td>\n",
              "      <td>0.010548</td>\n",
              "      <td>0.027262</td>\n",
              "      <td>0.050905</td>\n",
              "      <td>0.066405</td>\n",
              "      <td>0.129571</td>\n",
              "      <td>...</td>\n",
              "      <td>3.772524</td>\n",
              "      <td>2.748905</td>\n",
              "      <td>1.796452</td>\n",
              "      <td>1.089905</td>\n",
              "      <td>0.563190</td>\n",
              "      <td>0.239571</td>\n",
              "      <td>0.093524</td>\n",
              "      <td>0.024833</td>\n",
              "      <td>0.000857</td>\n",
              "      <td>0.001405</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.006143</td>\n",
              "      <td>0.035833</td>\n",
              "      <td>0.082357</td>\n",
              "      <td>0.114905</td>\n",
              "      <td>0.178714</td>\n",
              "      <td>0.301452</td>\n",
              "      <td>0.413643</td>\n",
              "      <td>0.513667</td>\n",
              "      <td>0.558833</td>\n",
              "      <td>0.677857</td>\n",
              "      <td>0.60281</td>\n",
              "      <td>0.489238</td>\n",
              "      <td>0.340214</td>\n",
              "      <td>0.219286</td>\n",
              "      <td>0.117095</td>\n",
              "      <td>0.059024</td>\n",
              "      <td>0.02019</td>\n",
              "      <td>0.017238</td>\n",
              "      <td>0.002857</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.887730</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.56812</td>\n",
              "      <td>1.626927</td>\n",
              "      <td>1.053972</td>\n",
              "      <td>0.043916</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.078072</td>\n",
              "      <td>0.232634</td>\n",
              "      <td>1.131661</td>\n",
              "      <td>2.310396</td>\n",
              "      <td>3.121847</td>\n",
              "      <td>3.259128</td>\n",
              "      <td>4.992894</td>\n",
              "      <td>...</td>\n",
              "      <td>26.957829</td>\n",
              "      <td>22.879248</td>\n",
              "      <td>18.595109</td>\n",
              "      <td>14.434439</td>\n",
              "      <td>10.517823</td>\n",
              "      <td>6.469315</td>\n",
              "      <td>3.976306</td>\n",
              "      <td>1.846016</td>\n",
              "      <td>0.139556</td>\n",
              "      <td>0.287891</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.949803</td>\n",
              "      <td>2.350859</td>\n",
              "      <td>3.934280</td>\n",
              "      <td>4.543583</td>\n",
              "      <td>5.856772</td>\n",
              "      <td>7.219742</td>\n",
              "      <td>8.928286</td>\n",
              "      <td>10.004069</td>\n",
              "      <td>10.129595</td>\n",
              "      <td>11.254931</td>\n",
              "      <td>10.69603</td>\n",
              "      <td>9.480066</td>\n",
              "      <td>7.950251</td>\n",
              "      <td>6.312890</td>\n",
              "      <td>4.633819</td>\n",
              "      <td>3.274488</td>\n",
              "      <td>1.75987</td>\n",
              "      <td>1.894498</td>\n",
              "      <td>0.414264</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>116.00000</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>216.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>157.000000</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>243.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>253.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>177.000000</td>\n",
              "      <td>231.000000</td>\n",
              "      <td>253.000000</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.00000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>253.000000</td>\n",
              "      <td>253.00000</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows Ã— 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              label   pixel0   pixel1  ...  pixel781  pixel782  pixel783\n",
              "count  42000.000000  42000.0  42000.0  ...   42000.0   42000.0   42000.0\n",
              "mean       4.456643      0.0      0.0  ...       0.0       0.0       0.0\n",
              "std        2.887730      0.0      0.0  ...       0.0       0.0       0.0\n",
              "min        0.000000      0.0      0.0  ...       0.0       0.0       0.0\n",
              "25%        2.000000      0.0      0.0  ...       0.0       0.0       0.0\n",
              "50%        4.000000      0.0      0.0  ...       0.0       0.0       0.0\n",
              "75%        7.000000      0.0      0.0  ...       0.0       0.0       0.0\n",
              "max        9.000000      0.0      0.0  ...       0.0       0.0       0.0\n",
              "\n",
              "[8 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bXzS-MEtG36"
      },
      "source": [
        "#We can see there is one column that has the label and the rest are the image pixels!"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "VICjzbGTsuo4",
        "outputId": "e0076885-84d8-44f0-f404-21ab58a73758"
      },
      "source": [
        "test_df.describe()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>pixel39</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel744</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001357</td>\n",
              "      <td>0.012500</td>\n",
              "      <td>0.016786</td>\n",
              "      <td>0.031714</td>\n",
              "      <td>0.056000</td>\n",
              "      <td>0.100464</td>\n",
              "      <td>0.166929</td>\n",
              "      <td>...</td>\n",
              "      <td>3.272536</td>\n",
              "      <td>2.371464</td>\n",
              "      <td>1.454357</td>\n",
              "      <td>0.846286</td>\n",
              "      <td>0.509750</td>\n",
              "      <td>0.254750</td>\n",
              "      <td>0.062107</td>\n",
              "      <td>0.015250</td>\n",
              "      <td>0.000786</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.005429</td>\n",
              "      <td>0.024179</td>\n",
              "      <td>0.036250</td>\n",
              "      <td>0.083143</td>\n",
              "      <td>0.134107</td>\n",
              "      <td>0.201071</td>\n",
              "      <td>0.325000</td>\n",
              "      <td>0.366714</td>\n",
              "      <td>0.468143</td>\n",
              "      <td>0.589429</td>\n",
              "      <td>0.656964</td>\n",
              "      <td>0.569714</td>\n",
              "      <td>0.464214</td>\n",
              "      <td>0.323679</td>\n",
              "      <td>0.164607</td>\n",
              "      <td>0.073214</td>\n",
              "      <td>0.028036</td>\n",
              "      <td>0.011250</td>\n",
              "      <td>0.006536</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.227093</td>\n",
              "      <td>1.566275</td>\n",
              "      <td>1.513515</td>\n",
              "      <td>2.674449</td>\n",
              "      <td>3.216234</td>\n",
              "      <td>4.549478</td>\n",
              "      <td>5.470524</td>\n",
              "      <td>...</td>\n",
              "      <td>25.211706</td>\n",
              "      <td>21.240003</td>\n",
              "      <td>16.643468</td>\n",
              "      <td>12.637953</td>\n",
              "      <td>9.963879</td>\n",
              "      <td>7.031504</td>\n",
              "      <td>3.040514</td>\n",
              "      <td>1.265562</td>\n",
              "      <td>0.131475</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.640468</td>\n",
              "      <td>2.234963</td>\n",
              "      <td>2.493982</td>\n",
              "      <td>3.777711</td>\n",
              "      <td>4.946940</td>\n",
              "      <td>6.262819</td>\n",
              "      <td>7.714814</td>\n",
              "      <td>8.243535</td>\n",
              "      <td>8.974038</td>\n",
              "      <td>10.488695</td>\n",
              "      <td>11.209508</td>\n",
              "      <td>10.204173</td>\n",
              "      <td>9.402197</td>\n",
              "      <td>7.878854</td>\n",
              "      <td>5.473293</td>\n",
              "      <td>3.616811</td>\n",
              "      <td>1.813602</td>\n",
              "      <td>1.205211</td>\n",
              "      <td>0.807475</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>236.000000</td>\n",
              "      <td>163.000000</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>253.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>252.000000</td>\n",
              "      <td>245.000000</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>253.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>253.000000</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>193.000000</td>\n",
              "      <td>187.000000</td>\n",
              "      <td>119.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows Ã— 784 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        pixel0   pixel1   pixel2  ...  pixel781  pixel782  pixel783\n",
              "count  28000.0  28000.0  28000.0  ...   28000.0   28000.0   28000.0\n",
              "mean       0.0      0.0      0.0  ...       0.0       0.0       0.0\n",
              "std        0.0      0.0      0.0  ...       0.0       0.0       0.0\n",
              "min        0.0      0.0      0.0  ...       0.0       0.0       0.0\n",
              "25%        0.0      0.0      0.0  ...       0.0       0.0       0.0\n",
              "50%        0.0      0.0      0.0  ...       0.0       0.0       0.0\n",
              "75%        0.0      0.0      0.0  ...       0.0       0.0       0.0\n",
              "max        0.0      0.0      0.0  ...       0.0       0.0       0.0\n",
              "\n",
              "[8 rows x 784 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56X_gu8FsySh"
      },
      "source": [
        "#In test there is no label "
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AUrI37vV8pw",
        "outputId": "bb7567ea-1f6e-4448-c139-758f7f4b765c"
      },
      "source": [
        "print(train_df.shape)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(42000, 785)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hU42tNbTtUGC",
        "outputId": "3de0f41f-a007-4934-edb2-5b65cd3a46d3"
      },
      "source": [
        "#check null value\r\n",
        "train_df.isnull().any().sum()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mY4KcT0ptij4",
        "outputId": "c81d6284-cd06-4c06-bd66-4c1d805c8348"
      },
      "source": [
        "\r\n",
        "test_df.isnull().any().sum()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zbb8dhjDt3hr"
      },
      "source": [
        "#setting seed value\r\n",
        "seed=22\r\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLrmVjpTuO3-"
      },
      "source": [
        "#split train test images\r\n",
        "#X is the pixels and Y is the label. In the data first col is only label and others are pixels. so 0 col for y and others for x\r\n",
        "X = train.iloc[:,1:] #first : for all row and second 1: for 1 to last col\r\n",
        "Y= train.iloc[: , 0]\r\n",
        "\r\n",
        "#spliting dataframes using train_test_split \r\n",
        "x_train , x_test , y_train , y_test = train_test_split(X ,Y ,test_size = 0.2 , random_state = seed)\r\n",
        "\r\n",
        "#random_state Controls the shuffling applied to the data before applying the split\r\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnQq4gxrasWT",
        "outputId": "a0d9ee8f-b9fb-4cf2-ff98-313c9789c28d"
      },
      "source": [
        "print(x_test.shape)\r\n",
        "print(x_train.shape)\r\n",
        "print(test_df.shape)\r\n",
        "\r\n",
        "#convert dataframe to numpy before reshaping it or doing other works\r\n",
        "\r\n",
        "x_test = x_test.to_numpy()\r\n",
        "x_train = x_train.to_numpy() \r\n",
        "test_df = test_df.to_numpy()\r\n",
        "print('done')\r\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8400, 784)\n",
            "(33600, 784)\n",
            "(28000, 784)\n",
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGwc1WlExyWq"
      },
      "source": [
        "#Reshaping Images\r\n",
        "#We have a 1D vector with 784 pixels and we have to reshape it to (28x28x1) before passing it to the CNN.\r\n",
        "\r\n",
        "#This is because Keras wants an Extra Dimension in the end for channels. \r\n",
        "#If this had been RGB images, there would have been 3 channels, but as MNIST is gray scale it only uses 1.\r\n",
        "\r\n",
        "\r\n",
        "##first param in reshape is number of examples. We can pass -1 here as we want numpy to figure that out by itself ###################\r\n",
        "# reshape(examples, height, width, channels)\r\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\r\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\r\n",
        "test_df=test_df.reshape(-1,28,28,1)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReNdy7BJ4zJa",
        "outputId": "0d8e0aa9-c350-41d3-f8ee-74b08a7d388f"
      },
      "source": [
        "print(x_train.shape)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(33600, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adX5PAXwJEEZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4868b1cc-8bc7-4122-8d89-c551badaa366"
      },
      "source": [
        "print(x_test.shape)\r\n",
        "print(test_df.shape)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8400, 28, 28, 1)\n",
            "(28000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aswcemhDhGu2"
      },
      "source": [
        "#Data augmentation is super important. In terms of Images it means we can increase the number of images our model sees.\r\n",
        "\r\n",
        "#This can be acheived by Rotating the Image, Flipping the Image, Zooming the Image, Changing light conditions, Cropping it etc.\r\n",
        "\r\n",
        "#Keep in mind doing all these things will not always help the model. \r\n",
        "#For example in our situation a vertical_flip would not be wise as 6's would become 9's and vice-versa\r\n",
        "\r\n",
        "datagen = ImageDataGenerator(\r\n",
        "    rotation_range = 10,\r\n",
        "    zoom_range = 0.1,\r\n",
        "    width_shift_range = 0.1,\r\n",
        "    height_shift_range = 0.1\r\n",
        "\r\n",
        ")"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Il1KnraFlBIU"
      },
      "source": [
        "#data normalization\r\n",
        "#Pixel values are often stored as integers in the range 0 to 255, which is the range that int-8 can offer.\r\n",
        "\r\n",
        "\r\n",
        "#Sets the value of inputs between 0-1\r\n",
        "#Helps Gradient Descent Converge much faster\r\n",
        "#Brings features to equal level and weightage\r\n",
        "#Helps remove distortians in an image caused by light and shadows\r\n",
        "#convert values to float as result will be a float. If not done vals are set to zero\r\n",
        "x_test = x_test.astype('float32')/255\r\n",
        "x_train = x_train.astype('float32')/255\r\n",
        "test_df = test_df.astype('float32')/255"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BeWwyVrnCCY"
      },
      "source": [
        "#fitting the Imagedatagenerator we defined above\r\n",
        "\r\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_0RwT94nVxJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "419b250c-a721-4ccb-bdf5-e1e086a1af69"
      },
      "source": [
        "#one hot encoding labels\r\n",
        "\r\n",
        "#to_categorical\r\n",
        "\r\n",
        "#The labels are given as integers between 0-9. We need to one hot encode them.\r\n",
        "#For example 4 looks like this: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\r\n",
        "#This is done so that we have labels for all the classes, and we can easily carry out the Error/Cost during BackPropogation.\r\n",
        "\r\n",
        "### we dont need to one hot in our x_train or x_test\r\n",
        "\r\n",
        "y_train = to_categorical(y_train , num_classes=10)\r\n",
        "y_test = to_categorical(y_test , num_classes=10)\r\n",
        "\r\n",
        "print(y_test[10])"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Qh1hmyWoh8b"
      },
      "source": [
        "#Building CNN Model\r\n",
        "#For image classification CNN's are the best\r\n",
        "\r\n",
        "#NOTE: the hardest part is picking right model by understanding the data rather than by tuning hyperparameters\r\n",
        "\r\n",
        "#A larger training dataset will really help CNN accuracy\r\n",
        "\r\n",
        "#Steps:\r\n",
        "\r\n",
        "#Use Sequential Keras API\r\n",
        "#Add Convolutional Layers - Building blocks of ConvNets and what do the heavy computation\r\n",
        "#Add Pooling Layers - Steps along image - reduces params and decreases likelihood of overfitting\r\n",
        "#Add Batch Normalization Layer - Scales down outliers, and forces NN to not relying too much on a Particular Weight\r\n",
        "#Add Dropout Layer - Regularization Technique that randomly drops a percentage of neurons to avoid overfitting (usually 20% - 50%)\r\n",
        "#Add Flatten Layer - Flattens the input as a 1D vector\r\n",
        "#Add Output Layer - Units equals number of classes. Sigmoid for Binary Classification, Softmax in case of Multi-Class Classification.\r\n",
        "#Add Dense Layer - Fully connected layer which performs a linear operation on the layer's input\r\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yIaUIq61p1Q"
      },
      "source": [
        " model = Sequential()\r\n",
        "\r\n",
        "model.add(Conv2D(32 , kernel_size=(3,3), activation ='relu' , padding='same' , input_shape = (28,28,1)))\r\n",
        "model.add(BatchNormalization())\r\n",
        "\r\n",
        "model.add(Conv2D(32,kernel_size=(3,3),activation='relu' , padding='same'))\r\n",
        "model.add(BatchNormalization())\r\n",
        "model.add(MaxPool2D(pool_size=(2,2) ,strides=2))\r\n",
        "model.add(Dropout(0.25))\r\n",
        "\r\n",
        "model.add(Conv2D(64,kernel_size=(3,3),activation='relu' , padding='same'))\r\n",
        "model.add(BatchNormalization())\r\n",
        "\r\n",
        "model.add(Conv2D(64,kernel_size=(3,3),activation='relu' , padding='same'))\r\n",
        "model.add(BatchNormalization())\r\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=2,padding='valid'))\r\n",
        "model.add( Dropout(0.25))\r\n",
        "\r\n",
        "model.add(Flatten())\r\n",
        "\r\n",
        "model.add(Dense(512,activation='relu'))\r\n",
        "model.add(BatchNormalization())\r\n",
        "model.add(Dropout(0.25))\r\n",
        "\r\n",
        "model.add(Dense(1024,activation='relu'))\r\n",
        "model.add(BatchNormalization())\r\n",
        "model.add(Dropout(0.5))             \r\n",
        "\r\n",
        "model.add(Dense(10,activation='softmax'))"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKTpXjN0tvKm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79a1a36b-e16f-4893-b432-dde86dcbaf16"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 28, 28, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 14, 14, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 512)               1606144   \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                10250     \n",
            "=================================================================\n",
            "Total params: 2,213,610\n",
            "Trainable params: 2,210,154\n",
            "Non-trainable params: 3,456\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKCVoU6wypKg"
      },
      "source": [
        "##Compiling Model (configure learning process)\r\n",
        "#Before training the model we need to make sure we specify how the model will \"learn\"\r\n",
        "\r\n",
        "#Specify the Optimizer - The optimizer help us minimize the error function. Examples - RMSprop, Adam, AdaGrad, AdaDelta\r\n",
        "##Specify Loss Function - For Binary Classification use \"binary_crossentropy\" and for Multi-class Classification use \"categorical_crossentropy\" ########\r\n",
        "#Specify the metrics to evaluate model performance\r\n",
        "#There are various metrics which we can use to evaluate the performance of ML algorithms, classification as well as regression algorithms.\r\n",
        "#We can use classification performance metrics such as Log-Loss, Accuracy, AUC(Area under Curve) etc.\r\n",
        "\r\n",
        "optimizer = Adam(learning_rate=0.001 , beta_1=0.9 , beta_2=0.999)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jo6jHfkATqO"
      },
      "source": [
        "#compile the model\r\n",
        "#Compile defines the loss function, the optimizer and the metrics. \r\n",
        "#You need a compiled model to train (because training uses the loss function and the optimizer).\r\n",
        "\r\n",
        "\r\n",
        "model.compile(optimizer=optimizer , loss ='categorical_crossentropy' , metrics=['accuracy'])"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADEtC8TVAaW_"
      },
      "source": [
        "#Learning Rate Decay\r\n",
        "#Many optimization algorithms have a constant learning rate, which will often not reach a local minima.\r\n",
        "\r\n",
        "#To implement Learning Rate Decay we can use either LearningRateScheduler or ReduceLRonPlateau.\r\n",
        "\r\n",
        "#LearningRateScheduler - takes the step decay function as argument and returns updated learning rates for use in optimzer at every epoch stage.\r\n",
        "\r\n",
        "#ReduceLRonPlateau - monitors a quantity and if no improvement is seen for a 'patience' number of epochs, then the learning rate is reduced by a factor specified manually."
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0gkc-lWFUp5"
      },
      "source": [
        "reduce_lr = LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMGG4r5rqxsi"
      },
      "source": [
        "#Early Stopping Rounds\r\n",
        "#I would still like to define an early stopping parameter to ensure that my model stops training once I have reached a point\r\n",
        "# where it is no longer necessary to continue training. This is another way to control overfitting.\r\n",
        "\r\n",
        "#Its important to note that we need to specify a validation dataset in the model to use an early_stopping callback\r\n",
        "\r\n",
        "#by default this is evaluated on 'val loss'\r\n",
        "\r\n",
        "early_stopping = EarlyStopping(\r\n",
        "    \r\n",
        "    restore_best_weights =True,\r\n",
        "    min_delta = 0.001, #min ammount of change to count as an improvement\r\n",
        "    patience = 20 # how many epochs to wait before stoping\r\n",
        ")\r\n",
        "\r\n"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YX91m4W1VWK",
        "outputId": "f207237a-b1d3-4628-df1f-68ba27819ccb"
      },
      "source": [
        "print(x_train.shape)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(33600, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ae0_Hz1vsQLc",
        "outputId": "38b0b7fd-58a3-416e-8ef9-05726358ef4b"
      },
      "source": [
        "#Since we have the LearningRateScheduler, if we dont use the early stopping callback in this model \r\n",
        "#we see an improvement from 96.4% to about 96.6% accuracy as we get closer and closer to the local minima.\r\n",
        "\r\n",
        "#fitting the model\r\n",
        "\r\n",
        "batch_size = 64\r\n",
        "epochs = 50\r\n",
        "x = x_train.shape[0]\r\n",
        "print(x)\r\n",
        "steps =(x_train.shape[0] // 64) "
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sarxFFmeuJNw",
        "outputId": "cb6e6809-b2ad-4397-b978-5ba6f0854648"
      },
      "source": [
        "a = x_train.shape[0] // 64\r\n",
        "print(a)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "525\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2tdngbmnNOy",
        "outputId": "8936913e-f4b7-4ba3-850a-225ff866ec06"
      },
      "source": [
        "#type(batch_size)\r\n",
        "#type(x_train)\r\n",
        "#batch_size = ' '.join( map (str,batch_size))\r\n",
        "print(batch_size)\r\n",
        "#batch_size = int(batch_size.split(' '))\r\n",
        "#print(batch_size)\r\n",
        "#int(batch_size)\r\n",
        "#print(batch_size.type())\r\n"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBjJLFKWs44w",
        "outputId": "568461d8-47e8-4e6b-beab-213a3cf8e970"
      },
      "source": [
        "history = model.fit_generator(\r\n",
        "    datagen.flow(x_train , y_train , batch_size=batch_size),########### datagen.flow()\r\n",
        "    epochs=epochs,\r\n",
        "    validation_data = (x_test , y_test),\r\n",
        "    steps_per_epoch = x_train.shape[0] // batch_size,\r\n",
        "    callbacks = [reduce_lr] \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        ")"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "525/525 [==============================] - 191s 360ms/step - loss: 0.7697 - accuracy: 0.7805 - val_loss: 1.1948 - val_accuracy: 0.7118\n",
            "Epoch 2/50\n",
            "525/525 [==============================] - 190s 361ms/step - loss: 0.1451 - accuracy: 0.9560 - val_loss: 0.0527 - val_accuracy: 0.9840\n",
            "Epoch 3/50\n",
            "525/525 [==============================] - 189s 359ms/step - loss: 0.1052 - accuracy: 0.9675 - val_loss: 0.0411 - val_accuracy: 0.9868\n",
            "Epoch 4/50\n",
            "525/525 [==============================] - 189s 361ms/step - loss: 0.0890 - accuracy: 0.9731 - val_loss: 0.0346 - val_accuracy: 0.9887\n",
            "Epoch 5/50\n",
            "525/525 [==============================] - 190s 361ms/step - loss: 0.0719 - accuracy: 0.9777 - val_loss: 0.0303 - val_accuracy: 0.9911\n",
            "Epoch 6/50\n",
            "525/525 [==============================] - 190s 362ms/step - loss: 0.0653 - accuracy: 0.9801 - val_loss: 0.0329 - val_accuracy: 0.9907\n",
            "Epoch 7/50\n",
            "525/525 [==============================] - 189s 361ms/step - loss: 0.0609 - accuracy: 0.9807 - val_loss: 0.0316 - val_accuracy: 0.9900\n",
            "Epoch 8/50\n",
            "525/525 [==============================] - 189s 359ms/step - loss: 0.0525 - accuracy: 0.9841 - val_loss: 0.0246 - val_accuracy: 0.9926\n",
            "Epoch 9/50\n",
            "525/525 [==============================] - 189s 360ms/step - loss: 0.0487 - accuracy: 0.9854 - val_loss: 0.0222 - val_accuracy: 0.9931\n",
            "Epoch 10/50\n",
            "525/525 [==============================] - 189s 360ms/step - loss: 0.0437 - accuracy: 0.9860 - val_loss: 0.0230 - val_accuracy: 0.9937\n",
            "Epoch 11/50\n",
            "525/525 [==============================] - 189s 361ms/step - loss: 0.0439 - accuracy: 0.9855 - val_loss: 0.0220 - val_accuracy: 0.9937\n",
            "Epoch 12/50\n",
            "525/525 [==============================] - 189s 360ms/step - loss: 0.0414 - accuracy: 0.9874 - val_loss: 0.0204 - val_accuracy: 0.9946\n",
            "Epoch 13/50\n",
            "525/525 [==============================] - 190s 362ms/step - loss: 0.0343 - accuracy: 0.9886 - val_loss: 0.0195 - val_accuracy: 0.9940\n",
            "Epoch 14/50\n",
            "525/525 [==============================] - 189s 360ms/step - loss: 0.0382 - accuracy: 0.9890 - val_loss: 0.0188 - val_accuracy: 0.9951\n",
            "Epoch 15/50\n",
            "525/525 [==============================] - 187s 357ms/step - loss: 0.0389 - accuracy: 0.9880 - val_loss: 0.0180 - val_accuracy: 0.9946\n",
            "Epoch 16/50\n",
            "525/525 [==============================] - 188s 358ms/step - loss: 0.0308 - accuracy: 0.9906 - val_loss: 0.0155 - val_accuracy: 0.9957\n",
            "Epoch 17/50\n",
            "525/525 [==============================] - 188s 358ms/step - loss: 0.0284 - accuracy: 0.9910 - val_loss: 0.0193 - val_accuracy: 0.9945\n",
            "Epoch 18/50\n",
            "525/525 [==============================] - 187s 357ms/step - loss: 0.0253 - accuracy: 0.9928 - val_loss: 0.0166 - val_accuracy: 0.9956\n",
            "Epoch 19/50\n",
            "525/525 [==============================] - 188s 357ms/step - loss: 0.0245 - accuracy: 0.9925 - val_loss: 0.0171 - val_accuracy: 0.9957\n",
            "Epoch 20/50\n",
            "525/525 [==============================] - 188s 358ms/step - loss: 0.0241 - accuracy: 0.9921 - val_loss: 0.0173 - val_accuracy: 0.9952\n",
            "Epoch 21/50\n",
            "525/525 [==============================] - 189s 361ms/step - loss: 0.0229 - accuracy: 0.9925 - val_loss: 0.0176 - val_accuracy: 0.9955\n",
            "Epoch 22/50\n",
            "525/525 [==============================] - 187s 356ms/step - loss: 0.0214 - accuracy: 0.9941 - val_loss: 0.0163 - val_accuracy: 0.9958\n",
            "Epoch 23/50\n",
            "525/525 [==============================] - 188s 358ms/step - loss: 0.0208 - accuracy: 0.9933 - val_loss: 0.0155 - val_accuracy: 0.9961\n",
            "Epoch 24/50\n",
            "525/525 [==============================] - 190s 361ms/step - loss: 0.0226 - accuracy: 0.9935 - val_loss: 0.0162 - val_accuracy: 0.9955\n",
            "Epoch 25/50\n",
            "525/525 [==============================] - 189s 360ms/step - loss: 0.0181 - accuracy: 0.9942 - val_loss: 0.0173 - val_accuracy: 0.9958\n",
            "Epoch 26/50\n",
            "525/525 [==============================] - 188s 359ms/step - loss: 0.0177 - accuracy: 0.9940 - val_loss: 0.0163 - val_accuracy: 0.9960\n",
            "Epoch 27/50\n",
            "525/525 [==============================] - 188s 359ms/step - loss: 0.0185 - accuracy: 0.9946 - val_loss: 0.0172 - val_accuracy: 0.9954\n",
            "Epoch 28/50\n",
            "525/525 [==============================] - 189s 360ms/step - loss: 0.0178 - accuracy: 0.9940 - val_loss: 0.0178 - val_accuracy: 0.9949\n",
            "Epoch 29/50\n",
            "525/525 [==============================] - 189s 361ms/step - loss: 0.0180 - accuracy: 0.9938 - val_loss: 0.0165 - val_accuracy: 0.9958\n",
            "Epoch 30/50\n",
            "525/525 [==============================] - 194s 369ms/step - loss: 0.0152 - accuracy: 0.9947 - val_loss: 0.0172 - val_accuracy: 0.9961\n",
            "Epoch 31/50\n",
            "525/525 [==============================] - 193s 368ms/step - loss: 0.0171 - accuracy: 0.9945 - val_loss: 0.0156 - val_accuracy: 0.9960\n",
            "Epoch 32/50\n",
            "525/525 [==============================] - 193s 369ms/step - loss: 0.0155 - accuracy: 0.9949 - val_loss: 0.0161 - val_accuracy: 0.9956\n",
            "Epoch 33/50\n",
            "525/525 [==============================] - 193s 367ms/step - loss: 0.0161 - accuracy: 0.9946 - val_loss: 0.0157 - val_accuracy: 0.9961\n",
            "Epoch 34/50\n",
            "525/525 [==============================] - 188s 358ms/step - loss: 0.0142 - accuracy: 0.9960 - val_loss: 0.0156 - val_accuracy: 0.9960\n",
            "Epoch 35/50\n",
            "525/525 [==============================] - 188s 357ms/step - loss: 0.0199 - accuracy: 0.9940 - val_loss: 0.0160 - val_accuracy: 0.9960\n",
            "Epoch 36/50\n",
            "525/525 [==============================] - 190s 361ms/step - loss: 0.0146 - accuracy: 0.9952 - val_loss: 0.0163 - val_accuracy: 0.9957\n",
            "Epoch 37/50\n",
            "525/525 [==============================] - 190s 362ms/step - loss: 0.0151 - accuracy: 0.9949 - val_loss: 0.0164 - val_accuracy: 0.9958\n",
            "Epoch 38/50\n",
            "525/525 [==============================] - 190s 363ms/step - loss: 0.0163 - accuracy: 0.9952 - val_loss: 0.0163 - val_accuracy: 0.9960\n",
            "Epoch 39/50\n",
            "525/525 [==============================] - 189s 360ms/step - loss: 0.0175 - accuracy: 0.9952 - val_loss: 0.0163 - val_accuracy: 0.9958\n",
            "Epoch 40/50\n",
            "525/525 [==============================] - 189s 359ms/step - loss: 0.0130 - accuracy: 0.9956 - val_loss: 0.0165 - val_accuracy: 0.9960\n",
            "Epoch 41/50\n",
            "525/525 [==============================] - 195s 372ms/step - loss: 0.0133 - accuracy: 0.9958 - val_loss: 0.0162 - val_accuracy: 0.9958\n",
            "Epoch 42/50\n",
            "525/525 [==============================] - 193s 368ms/step - loss: 0.0155 - accuracy: 0.9953 - val_loss: 0.0163 - val_accuracy: 0.9960\n",
            "Epoch 43/50\n",
            "525/525 [==============================] - 192s 366ms/step - loss: 0.0132 - accuracy: 0.9951 - val_loss: 0.0161 - val_accuracy: 0.9960\n",
            "Epoch 44/50\n",
            "525/525 [==============================] - 189s 361ms/step - loss: 0.0142 - accuracy: 0.9956 - val_loss: 0.0161 - val_accuracy: 0.9960\n",
            "Epoch 45/50\n",
            "525/525 [==============================] - 192s 366ms/step - loss: 0.0131 - accuracy: 0.9962 - val_loss: 0.0161 - val_accuracy: 0.9961\n",
            "Epoch 46/50\n",
            "525/525 [==============================] - 194s 369ms/step - loss: 0.0152 - accuracy: 0.9952 - val_loss: 0.0163 - val_accuracy: 0.9960\n",
            "Epoch 47/50\n",
            "525/525 [==============================] - 192s 366ms/step - loss: 0.0126 - accuracy: 0.9961 - val_loss: 0.0161 - val_accuracy: 0.9961\n",
            "Epoch 48/50\n",
            "525/525 [==============================] - 193s 368ms/step - loss: 0.0132 - accuracy: 0.9956 - val_loss: 0.0161 - val_accuracy: 0.9960\n",
            "Epoch 49/50\n",
            "525/525 [==============================] - 192s 366ms/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.0161 - val_accuracy: 0.9960\n",
            "Epoch 50/50\n",
            "525/525 [==============================] - 194s 369ms/step - loss: 0.0156 - accuracy: 0.9951 - val_loss: 0.0161 - val_accuracy: 0.9960\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AblywKIcxowj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8c3287b-ea79-4d90-d393-df89ef80f11b"
      },
      "source": [
        "print('done')"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcYd93tP0M7D",
        "outputId": "56168871-ccb6-4099-f0c6-5f5606fdec0f"
      },
      "source": [
        "evaluate = model.evaluate(x_test , y_test)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "263/263 [==============================] - 11s 40ms/step - loss: 0.0161 - accuracy: 0.9960\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "s4cCbT-uXw8F",
        "outputId": "916edcb9-c90a-4bab-b052-3e1af71d6cd2"
      },
      "source": [
        "plt.figure(figsize=(20,5))\r\n",
        "plt.plot(history.history['loss'])\r\n",
        "plt.plot(history.history['val_loss'])\r\n",
        "plt.xlabel('Epochs')\r\n",
        "plt.ylabel('Loss')\r\n",
        "plt.legend(['Train' , 'Test'])\r\n",
        "plt.grid()\r\n",
        "plt.show()"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "e8e_aL9gaC5J",
        "outputId": "25b41a7e-0fc6-49b1-acdf-55c7fb726be3"
      },
      "source": [
        "plt.figure(figsize=(20,5))\r\n",
        "plt.plot(history.history['accuracy'])\r\n",
        "plt.plot(history.history['val_accuracy'])\r\n",
        "plt.xlabel('Epochs')\r\n",
        "plt.ylabel('accuracy')\r\n",
        "plt.legend(['Train' , 'Test'])\r\n",
        "plt.grid()\r\n",
        "plt.show()"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyvzMI1EnbHQ"
      },
      "source": [
        "#Since the validation_accuracy and the accuracy are really close together we can conclude that we are not overfitting the data."
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "hJio_Kwqojis",
        "outputId": "e2f2058a-cda2-444e-b8e1-c926a6b4567e"
      },
      "source": [
        "import cv2\r\n",
        "\r\n",
        "# Generate Random Numbers\r\n",
        "rdm = np.random.randint(0,42000,size=4)\r\n",
        "\r\n",
        "from google.colab.patches import cv2_imshow\r\n",
        "\r\n",
        "\r\n",
        "cv2_imshow(train_df.drop('label',axis=1).values[[100]].reshape(28,28))\r\n",
        "cv2_imshow(train_df.drop('label',axis=1).values[[20]].reshape(28,28))\r\n"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA/klEQVR4nGNgGMrAbsO/f0/UsMmwhJ/5+nd1z78DmFKiDXf+PltSJKH67+suNCm+9md/3xWIMDD0/v3396kIipzei39/F2kyMDAwqD3+9/cGipzRq3+v/KDsmP//5iPLKTz/+5IXypa78e+uGLKky9+34lCm79W/nz1RTJ349zUDAwMDA7vwrK9///bBvcbAwMDA8ICBLZpxtYdwrv5/Bob9Paj+0Lj579//f/+ObI3Z8e+TFHoAiOXkrI0UYmGwe/+3CV0ODjb8vcCBSy7/398IXHJ6L/5t5cYleeLffyNccmY//7Yx4ZJc8/evHi45hpt/t6IKoBpzBqdGEgEARCtiVsetJ28AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F8D524F2DD8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA/ElEQVR4nM3RIUhDcRDH8a8owkMejz/DYF0YY2V53WJUkywZ9oJGg0kYSwanQYZ1yILBaBCxGRYEBQ0G0Rn+wsOVTV0QvdNk0P9VwUsHn3C/u4P/W/k8UNncH53nTC/vvslDlk3OTwc0XlV5rrvlQUvXAqyI7hWgLOKLvy2+0zZAR30aDhSJwDXee3NGGhFHrqu9khE1PpF+rStnwTwA3NWnqjcJiFTk2tk21dKbTGo2bohPVuXYtBX14PqPiWGNl04C8f3QOPu6XkRAU7ZDc0++CKSD25kQm5oC9dGpYVweEC0davvHIye+m7HF6uzrwtGHtceW+J2CBX9QX7FjXl9u3zRNAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F8D524F2828>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdTFJlGM-cZX"
      },
      "source": [
        ""
      ],
      "execution_count": 122,
      "outputs": []
    }
  ]
}